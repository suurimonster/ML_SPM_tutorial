{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c413a97-9579-4950-9166-1d80256b629b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Machine learning and microscopy\n",
    "=====================\n",
    "\n",
    "Moving to machine learning\n",
    "------------\n",
    "\n",
    "* Machine learning at heart is a software toolset to apply statistical methods to find patterns in data.\n",
    "* “The ability [of machine learning] to automatically identify patterns in data [...] is particularly important when the expert knowledge is incomplete or inaccurate, when the amount of available data is too large to be handled manually, or when there are exceptions to the general cases” [1]\n",
    "\n",
    "![ML](images/machine_learning_joke.jpg)\n",
    "\n",
    "Why NOT use maching learning?\n",
    "------------\n",
    "\n",
    "* It is very tempting to start applying machine learning approaches to everything, but it is critical to step back and see if it makes sense.\n",
    "* Some major reasons NOT to apply an machine learning approach would be:\n",
    "    * There are existing methods that do the job well - there is no point inventing a square wheel.\n",
    "    * You don't have enough data - in general you want to have a ratio of 10:1 between *datapoints* and *features*.\n",
    "    * Your data is poorly organized or heavily biased - if you are not sure about the history and compatibility of your data you will not be able to trust any of your predictions.\n",
    "\n",
    "[1]: Yip KY, Cheng C, Gerstein M. Machine learning and genome annotation: a match meant to be? Genome Biol. 2013;14(5):205."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008c56d9-801a-4c7c-95ba-2b35e3701a89",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Recent examples\n",
    "====================\n",
    "\n",
    "Image segmentation\n",
    "---------------------\n",
    "\n",
    "* A very common application of machine learning in microscopy is image segmentation i.e. automatically detecting features in images.\n",
    "* This is generally achieved using Convolutional Neural Networks (CNN) and the approach is the backbone for all the animal classification methods you have likely seen already.\n",
    "* This classification is an example of *supervised learning*, where the training data is labelled by the user. The algorithm then learns this classification and is able to make accurate predictions on new data.\n",
    "* For an example, we use the U-Net method[1], which is a powerful approach, widely used in many CNN applications. For biomedial imaging, they actually broke some of our inital rules...they had very little data, but used extensive *augmentation* to expand the valid data set. In particular (and general to microscopy of soft systems) they introduced:\n",
    "    * shift and rotation invariance \n",
    "    * gray value variations\n",
    "    * random elastic deformations\n",
    "* It is not perfect (77%), but much better than any alternatives at that time.\n",
    "\n",
    "![segment](images/segment.png)\n",
    "\n",
    "[1]: Ronneberger, O., Fischer, P. & Brox, T. U-Net: Convolutional Networks for Biomedical Image Segmentation. arXiv:1505.04597 [cs] (2015).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe9be1d-3a3b-4229-9fce-95bb8b7c5b84",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Cell classification\n",
    "---------------------\n",
    "\n",
    "* In terms of searching for patterns in images that demonstrate a correlation between a measurement and a hypothesis, machine learning image analysis can also be very powerful.\n",
    "* In the example, they looked at multi-channel AFM data of healthy and cancerous (fixed) cells [1].\n",
    "\n",
    "![cancer_cells](images/cancer_cells.png)\n",
    "\n",
    "* Model was trained on the imaging channels independently and in combination, and the resultant classification accuracy was studied as a function of measured parameters. Very high accuracy was achieved using a combination of channels.\n",
    "\n",
    "![cancer_acc](images/cancer_acc.png)\n",
    "\n",
    "[1]: Prasad, S. et al. Atomic Force Microscopy Detects the Difference in Cancer Cells of Different Neoplastic Aggressiveness via Machine Learning. Advanced NanoBiomed Research 1, 2000116 (2021).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170fe77b-e966-4209-8c64-76da6401f9dd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Active learning\n",
    "--------------------\n",
    "\n",
    "* A powerful development in experimental design is the introduction of active learning (also referred to as *Bayesian Optimisation*), where measurements are dynamically chosen to optimise the information obtained.\n",
    "* In piezoresponse force microscopy, this has been used to automate the measurement of spectra at regions of specific interest [1]. The system is first trained on known surface features and spectra.\n",
    "\n",
    "![active_model](images/active_model.png)\n",
    "\n",
    "* Then, when it is linked to the driving software of an SPM, the network itself can make a decision about the most useful place to measure the spectra. These *decisions* can then actually tell us something about the correlation between image features and the nature of the spectra.\n",
    "\n",
    "![active_image](images/active_image.png)\n",
    "\n",
    "[1]: Liu, Y., Kelley, K.P., Vasudevan, R.K. et al. Experimental discovery of structure–property relationships in ferroelectric materials via active learning. Nat Mach Intell 4, 341–350 (2022)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44bd44f-e736-45cc-b831-29115336af33",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Machine learning methods\n",
    "============================\n",
    "\n",
    "* There are a wide variety of machine learning approaches and as a general rule it is better to use the simplest one that works. In microscopy, since we are often working with images, then Neural Networks (NN) are an obvious place to start, as there has been an enormous effort in recent years to optimise NN tools for image analysis. They also play role in all the examples/tutorials we are considering. Do NOT use them by default...\n",
    "\n",
    "Neural Networks\n",
    "-------------------\n",
    "\n",
    "* The starting point of a neural network is the neuron itself (called a *perceptron* in the context of machine learning) - it takes inputs, applies some operations to them and produces an output [1].\n",
    "\n",
    "![neuron](images/perceptron.svg)\n",
    "\n",
    "* First each input $x_1,x_2$ is multiplied by weights $w_1,w_2$. Then all the weighted inputs are added together with a bias $b$ and an activation function $f$ is applied to the total:\n",
    "\n",
    "$y = f((w_1*x_1)+(w_2*x_2) + b$)\n",
    "\n",
    "* The bias reflects your pre-assumptions in the model i.e. the higher it is, the more you think you know what the answer should be, and the weights determine the strength of connection between this input and the output. These are the *hyper-parameters* that will be optimized.\n",
    "\n",
    "* The activation function turns an unbounded input into a controllable, bounded input. A commonly used example would be a sigmoid function.\n",
    "\n",
    "[1]: Neural Networks from Scratch - https://victorzhou.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91801177-14ab-46b9-afd7-41add675977f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "\n",
    "x = np.linspace(-10, 10, 100) \n",
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "a = sigmoid(x)\n",
    "\n",
    "plt.figure(figsize=(12,7)) # set the figsize\n",
    "plt.plot(x, a) \n",
    "plt.xlabel(\"x\") \n",
    "plt.ylabel(\"sigmoid(x)\")\n",
    "plt.rc('font',size=16) # set the font size\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e02295-a49d-4e04-83e3-01ff4ae08604",
   "metadata": {},
   "source": [
    "* We can then code a very simple neuron as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ab0ba1-0759-441e-9df8-8b4e8c00016a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Neuron: # classes are a powerful aspect of python that allows inherited characteristics\n",
    "  def __init__(self, weights, bias):\n",
    "    self.weights = weights\n",
    "    self.bias = bias\n",
    "\n",
    "  def feedforward(self, inputs): # passing inputs to get an output is known as \"feed forward\"\n",
    "    # Weight inputs, add bias, then use the activation function\n",
    "    total = np.dot(self.weights, inputs) + self.bias\n",
    "    return sigmoid(total)\n",
    "\n",
    "weights = np.array([0, 1]) # w1 = 0, w2 = 1\n",
    "bias = 4                   # b = 4\n",
    "n = Neuron(weights, bias)\n",
    "\n",
    "x = np.array([2, 3])       # x1 = 2, x2 = 3\n",
    "print(n.feedforward(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07d2020-dfc2-4a06-8699-b1bca6bcc627",
   "metadata": {},
   "source": [
    "* A neural network is just formed by combing neurons and connecting them.\n",
    "\n",
    "![nn](images/network.svg)\n",
    "\n",
    "* Again, we can make a simple code that implements this network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f337e5fa-4886-4af1-838d-1be081ad3c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Neural_Network:\n",
    "  '''\n",
    "  A neural network with:\n",
    "    - 2 inputs\n",
    "    - a hidden layer with 2 neurons (h1, h2)\n",
    "    - an output layer with 1 neuron (o1)\n",
    "  Each neuron has the same weights and bias:\n",
    "    - w = [0, 1]\n",
    "    - b = 0\n",
    "  '''\n",
    "  def __init__(self):\n",
    "    weights = np.array([0, 1])\n",
    "    bias = 0\n",
    "\n",
    "    # The Neuron class here is from the previous code sample\n",
    "    self.h1 = Neuron(weights, bias)\n",
    "    self.h2 = Neuron(weights, bias)\n",
    "    self.o1 = Neuron(weights, bias)\n",
    "\n",
    "  def feedforward(self, x):\n",
    "    out_h1 = self.h1.feedforward(x)\n",
    "    out_h2 = self.h2.feedforward(x)\n",
    "\n",
    "    # The inputs for o1 are the outputs from h1 and h2\n",
    "    out_o1 = self.o1.feedforward(np.array([out_h1, out_h2]))\n",
    "\n",
    "    return out_o1\n",
    "\n",
    "network = Neural_Network()\n",
    "x = np.array([2, 3])\n",
    "print(network.feedforward(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f73699-34b6-45e5-95c5-5e2d04da31b0",
   "metadata": {},
   "source": [
    "* This appears very abstract, but if we were classifying articles as either from physics or biology based on the number of equations in them, we might assign an output of (0) to physics and (1) to biology, and then train the network on data on equation numbers per article from each field. The training would attempt to minimize the *loss* in the output with respect to the parameters of the model.\n",
    "* The number of hidden layers (the layers between input and output) determine the *depth* of the network and is the source of the term *deep learning*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4909e6e3-20d6-4b51-94ac-a7e5947d4f52",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Tutorial 1\n",
    "\n",
    "### Iris flower data set\n",
    "\n",
    "The Iris flower data set or Fisher's Iris data set is a multivariate data set introduced by the British statistician and biologist Ronald Fisher in his 1936 paper *\"The use of multiple measurements in taxonomic problems as an example of linear discriminant analysis\"*.\n",
    "\n",
    "The data set consists of 50 samples from each of three species of Iris (Iris setosa, Iris virginica and Iris versicolor). Four features were measured from each sample: the length and the width of the sepals and petals, in centimeters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a032139a-120e-4cba-9829-2a134136ec9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "with open(\"examples/data/iris.pkl\", \"rb\") as fio:\n",
    "    iris = pickle.load(fio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a01611-eafc-4128-9c2a-ef1149b0abb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets see the data\n",
    "from pprint import pprint\n",
    "pprint(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800f8c62-51a5-4cae-9223-a151578a386a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input data\n",
    "x = iris[\"data\"]\n",
    "input_shape = (4,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d9fe57-1dbb-450a-a68e-0ab2911dca0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output data\n",
    "target = iris[\"target\"]\n",
    "num_classes = 3\n",
    "# one-hot representation\n",
    "y = keras.utils.to_categorical(target, num_classes)\n",
    "\n",
    "print(f\"targets: {target[:5]}\\none-hot rep:{y[:5, :]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5561ad8-9c15-4b2d-90f7-68da24dc4ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle\n",
    "shuffle_indices = np.random.permutation(np.arange(len(target)))\n",
    "x = x[shuffle_indices]\n",
    "y = y[shuffle_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ddad2a-760c-435d-ac5e-2821621ee84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_train split 80-20\n",
    "split = int(len(target) * 0.8)\n",
    "x_train, x_test, y_train, y_test = x[:split, :], x[split:, :], y[:split, :], y[split:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288d2652-30b4-4065-b167-5d91821f3678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Dense(8, activation=\"relu\"),\n",
    "        layers.Dense(num_classes, activation=\"softmax\")\n",
    "    ]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0783db-8763-42d9-b92f-99680ede9961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the network\n",
    "batch_size = 5 # number of images in each batch used for optimisation - balance speed of each epoch against convergence to high accuracy\n",
    "epochs = 200\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd386c26-91fc-4bcf-ace6-0758140cb844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b72472-5432-4471-b25c-eeabfaeac95d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Convolutional neural networks\n",
    "----------------------------------\n",
    "\n",
    "* Nearly all image analysis relies on using Convolutional neural networks (CNN) rather than standard neural networks. This two main reasons:\n",
    "    * Images are big - imagine building a neural network to process a 224x224 color image - including the 3 color channels (RGB) in the image, that comes out to 224 x 224 x 3 = 150 528 input features. A typical hidden layer in such a network might have 1024 nodes, so we’d have to train 150 528 x 1024 = 150+ million weights for the first layer alone. Our network would be huge and nearly impossible to train.\n",
    "    * Positions can change - if you trained a network to detect dogs, you’d want it to be able to a detect a dog regardless of where it appears in the image. Imagine training a network that works well on a certain dog image, but then feeding it a slightly shifted version of the same image. The dog would not activate the same neurons, so the network would react completely differently.\n",
    "* What we really want to do is learn characteristic features within our training images that would be general to the subject of interest rather than the image itself.\n",
    "\n",
    "*Convolutions*\n",
    "\n",
    "* A CNN basically convolves the image with a filter that will extract features. For example, the Sobel filter:\n",
    "\n",
    "![sobel](images/vertical-sobel.svg)\n",
    "\n",
    "when applied to a simple greyscale image, convolves it into a smaller matrix (using *padding* i.e. adding zeroes at the edges, would allow us to sample more pixels):\n",
    "\n",
    "![convolve](images/convolve-output.gif)\n",
    "\n",
    "at each step it is just performing an element-wise multiplication between the values in the filter and their corresponding values in the image, and then summing up all the element-wise products to get the new output.\n",
    "\n",
    "* What does this actually do?\n",
    "\n",
    "![lenna](images/lenna+vertical.png)\n",
    "\n",
    "The Sobel filter is an edge detector - the image has been transformed into a set of *edge features*.\n",
    "\n",
    "*Pooling*\n",
    "\n",
    "* It is obvious to us (but not to the *machine*) that many features are connected such that many neighbouring pixels have similar values. In the context of the edge detection filter, if we find a strong edge a location, it is pretty likely that the edge will also be present one pixel away.\n",
    "\n",
    "* To avoid duplicating features, this is normally handled by using *pooling* of neighbouring pixels to there maximum, minimum or average (max-, min- and mean-pooling).\n",
    "\n",
    "![pool](images/pool.gif)\n",
    "\n",
    "*Softmax*\n",
    "\n",
    "* Finally, we need an activation function, just as in the standard NN. A commonly used function for CNNs is Softmax, which has the following form:\n",
    "\n",
    "${Softmax}(x_{i}) = \\frac{\\exp(x_i)}{\\sum_j \\exp(x_j)}$\n",
    "\n",
    "* Softmax produces a value from 0 to 1, as for the Sigmoid, but also the outputs add up to 1, so it has the form of a probability - this is not needed, but it allows for the use of *cross entropy loss*, which includes a component of prediction confidence. So the very basic form of a CNN is the following:\n",
    "\n",
    "![cnn](images/cnn.svg)\n",
    "\n",
    "* Here we start with a 28x28 image and convolve it with 8 filters. Using a maximum pooling with size 2 reduces the image to 13x13. There are 10 Softmax nodes, which would assume we are trying to classify our data into 10 classes. The final output from Softmax for a given image would be the node with the highest probability i.e. the class prediction.\n",
    "\n",
    "*Training*\n",
    "\n",
    "* Before we actually let you play around with training your own network, a few comments the process itself. It generally consists of two phases:\n",
    "    * A forward phase, where the input is passed completely through the network - key values are stored in preparation for the backwards pass.\n",
    "    * A backward phase, where gradients are backpropagated (backprop) and weights are updated. During this phase, each layer will receive the gradient of loss with respect to its outputs and return the gradient of loss with respect to its inputs - this establishes the dependence of loss on our parameters and allows for optimisation (with a standard optimiser like ADAM).\n",
    "* The basic code for CNN training would have this form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf0afe7-2185-4f2c-b652-b99a4042c232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feed forward\n",
    "out = conv.forward(image)\n",
    "out = pool.forward(out)\n",
    "out = softmax.forward(out)\n",
    "\n",
    "# Calculate initial gradient\n",
    "gradient = np.zeros(10)\n",
    "# ...\n",
    "\n",
    "# Backprop\n",
    "gradient = softmax.backprop(gradient)\n",
    "gradient = pool.backprop(gradient)\n",
    "gradient = conv.backprop(gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad94fb9-baea-4d09-b102-cf90bca2eee7",
   "metadata": {},
   "source": [
    "* The core of training is in the `conv.backprop` step, as any changes in the filter weights is effectively changing the nature of the filters and the type of features associated with them.\n",
    "* When really applying these methods in a scientific context, it is much more efficient to use highly optimised models, such as `tensorflow`. As in tutorial 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71612c5-2c32-45c4-90a1-217f53143185",
   "metadata": {},
   "source": [
    "## Example \n",
    "=====================\n",
    "\n",
    "### CO functionalised AFM tip classification\n",
    "An automated solution for carbon monoxide functionalization which combines machine learning descriptors with automated software control of the tip preparation process. \n",
    "\n",
    "![Schematic](images/CO-tip-evaluator.png)\n",
    "\n",
    "[1] Alldritt, Benjamin, et al. \"Automated tip functionalization via machine learning in scanning probe microscopy.\" Computer Physics Communications 273 (2022): 108258."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4c5b182-cfd1-47f1-b3eb-731d4b2a7615",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "\n\nIMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!\n\nImporting the numpy C-extensions failed. This error can happen for\nmany reasons, often due to issues with your setup or how NumPy was\ninstalled.\n\nWe have compiled some common reasons and troubleshooting tips at:\n\n    https://numpy.org/devdocs/user/troubleshooting-importerror.html\n\nPlease note and check the following:\n\n  * The Python version is: Python3.7 from \"/opt/anaconda3/bin/python\"\n  * The NumPy version is: \"1.22.3\"\n\nand make sure that they are the versions you expect.\nPlease carefully study the documentation linked above for further help.\n\nOriginal error was: No module named 'numpy.core._multiarray_umath'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.10/site-packages/numpy/core/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmultiarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/site-packages/numpy/core/multiarray.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moverrides\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_multiarray_umath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/site-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m from numpy.core._multiarray_umath import (\n\u001b[0m\u001b[1;32m      7\u001b[0m     add_docstring, implement_array_function, _get_implementing_args)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy.core._multiarray_umath'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-34d97139937c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# data ingestion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/site-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_distributor_init\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/site-packages/numpy/core/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m \"\"\" % (sys.version_info[0], sys.version_info[1], sys.executable,\n\u001b[1;32m     48\u001b[0m         __version__, exc)\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0menvkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menv_added\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: \n\nIMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!\n\nImporting the numpy C-extensions failed. This error can happen for\nmany reasons, often due to issues with your setup or how NumPy was\ninstalled.\n\nWe have compiled some common reasons and troubleshooting tips at:\n\n    https://numpy.org/devdocs/user/troubleshooting-importerror.html\n\nPlease note and check the following:\n\n  * The Python version is: Python3.7 from \"/opt/anaconda3/bin/python\"\n  * The NumPy version is: \"1.22.3\"\n\nand make sure that they are the versions you expect.\nPlease carefully study the documentation linked above for further help.\n\nOriginal error was: No module named 'numpy.core._multiarray_umath'\n"
     ]
    }
   ],
   "source": [
    "# data ingestion\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def add_norm_CO(X_):\n",
    "    \"\"\" Normalise input image \"\"\"\n",
    "    sh = X_.shape\n",
    "\n",
    "    for j in range(sh[0]):\n",
    "        mean=np.mean(X_[j,:,:])            \n",
    "        sigma=np.std(X_[j,:,:])          \n",
    "        X_[j,:,:]-= mean\n",
    "        X_[j,:,:]= X_[j,:,:]/ sigma\n",
    "\n",
    "dataX = []\n",
    "file_names = []\n",
    "    \n",
    "for filename in os.listdir(\"examples/images/tip_classification\"):\n",
    "    image_path = os.path.join(\"examples\", \"images\", \"tip_classification\", filename)\n",
    "    image = np.array((Image.open(image_path).resize((16, 16), Image.ANTIALIAS))).astype(np.float32)\n",
    "    dataX.append(np.flipud(image))\n",
    "    file_names.append(filename)\n",
    "dataX = np.expand_dims(np.array(dataX), axis = 1)\n",
    "add_norm_CO(dataX)\n",
    "print (f'dataX: {dataX.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b83395b-71e6-4a25-99b5-18a97bd6266a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "model = keras.models.load_model(\"examples/models/tip_classifier.h5\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99f9d30-30bc-4e60-9188-f74e1e6c4ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "outputs = model.predict_on_batch(dataX)\n",
    "probs = np.squeeze(np.array(outputs))\n",
    "preds = np.squeeze(np.round(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd44a039-1d08-4262-8810-99a635a7cb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting\n",
    "from matplotlib import cm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_preds_with_title(dataX,probs,file_names, cmap=cm.gray):\n",
    "    cols = 10\n",
    "    rows = -(-len(file_names) // cols)\n",
    "    fig = plt.figure(figsize=(3.0*cols,3.0*rows))\n",
    "    \n",
    "    for i in range(len(file_names)):\n",
    "        sp = fig.add_subplot(rows,cols,i+1)#, origin=\"lower\"\n",
    "        sp.imshow(dataX[i,0,:,:], cmap = cmap)   \n",
    "        sp.axis('Off')\n",
    "        desc = file_names[i].split(\"-\")[0][:-1]\n",
    "        sp.set_title(f'pred = {probs[i]: 0.3f}\\ntarg = {desc} tip') \n",
    "    \n",
    "    save_name = 'predicted.png'\n",
    "    # plt.savefig('./'+save_name, bbox_inches='tight', dpi=200)\n",
    "    plt.show()\n",
    "    # plt.close()\n",
    "\n",
    "plot_preds_with_title(dataX,probs,file_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde94af3-c9e2-42ca-b8cf-2ebc0b975afa",
   "metadata": {},
   "source": [
    "## Tutorial 2\n",
    "\n",
    "### Number recognition\n",
    "Here is a CNN trained to recognize digits from images of handwritten numbers: \n",
    "\n",
    "![digits](images/digits.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c16c2f-b51d-4ed7-8abc-79635914bf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data and scale it to convenient shapes\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Model / data parameters\n",
    "num_classes = 10\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "# the data, split between train and test sets - test on data not in your training data!\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Scale images to the [0, 1] range\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "# Make sure images have shape (28, 28, 1)\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(x_train.shape[0], \"train samples\")\n",
    "print(x_test.shape[0], \"test samples\")\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cc186e-ce2d-4e63-b444-ee0184110194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the model\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(), #matching array shapes\n",
    "#        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0688ab2-73e4-4e92-9ae2-aa9ff60e6a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the CNN\n",
    "batch_size = 10000 # number of images in each batch used for optimisation - balance speed of each epoch against convergence to high accuracy\n",
    "epochs = 3\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384ce876-97f3-4928-ac70-ca2c5f540944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b53c10-bfce-4d3d-9ae4-7c0d234898a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
