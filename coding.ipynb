{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Machine learning and microscopy\n",
    "=====================\n",
    "\n",
    "Introduction\n",
    "------------\n",
    "\n",
    "* An introduction to some of the key ideas in applying machine learning to the analysis of microscopy data.\n",
    "* Format is a brief introduction from me and then you start working with the tutorials.\n",
    "* Feel free to move ahead to the advanced topics if you wish.\n",
    "\n",
    "![Comp_Phys](images/comp_phys.png)\n",
    "\n",
    "* Morning\n",
    "    * Python and jupyter notebooks\n",
    "    * Reading data - parsing files\n",
    "    * Image analysis\n",
    "* Afternoon\n",
    "    * Machine learning - how and why?\n",
    "    * Convolutional neural networks\n",
    "    * Reinforcement learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Why Python?\n",
    "-----------\n",
    "\n",
    "![python](images/python_logo.png)\n",
    "\n",
    "* Scientific analysis is performed with a wide variety of languages and often the best performance can be achieved by matching the problem and language.\n",
    "* However, this is not generally practical and most efforts in modern computational analysis are based on Python:\n",
    "    * Easy to learn.\n",
    "    * Easy to read (critical, as most research is collaborative).\n",
    "    * Powerful scientific tools - most of the critical elements we need are already included, while well-supported libraries offer the rest.\n",
    "    * It's free...\n",
    " \n",
    "![python_comic](images/python_comic.png)\n",
    " \n",
    "We also assume you know how to code to some degree, so we will focus on learning to use Python for scientific analysis rather than an introduction to Python in general.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "An example from history\n",
    "-----------------------\n",
    "\n",
    "In 1888 Johannes Rydberg published his famous equation describing the wavelengths of light emitted from a hydrogen atom:\n",
    "\n",
    "$\\frac{1}{\\lambda}=R\\left(\\frac{1}{m^2}-\\frac{1}{n^2}\\right)$\n",
    "\n",
    "where $R$ is the Rydberg constant $R=1.097 \\times 10^{-2}$nm$^{-1}$, and $m$ and $n$ are positive integers. For a given value of $m$, the wavelengths $\\lambda$ given by this formula for all $n \\gt m$ form a series. The first three of these series, for $m=1,2,3$, are named after their discoverers Lyman, Balmer and Paschen respectively.\n",
    "\n",
    "Let's make a simple Python code that solves this equation for $m=1,2,3$ and outputs the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = 1.097e-2\n",
    "for m in [1,2,3]:\n",
    "    print(\"Series for m =\",m)\n",
    "    for k in [1,2,3,4,5,6]:\n",
    "        n = m + k \n",
    "        invlambda = R*(1/m**2-1/n**2)\n",
    "        print(\" \",1/invlambda,\"nm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The agreement with experiment is actually remarkably good, with the differences due to small details of the electronic structure (spin, relativistic corrections, hyperfine splitting)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Practical Python test\n",
    "---------------------\n",
    "\n",
    "As a test that you can actually get Python code running on your system, try to re-run the Rydberg code yourself. You have several options for running Python:\n",
    "\n",
    "* Just type `python` at the command prompt and it should give you something like this:\n",
    "\n",
    "```\n",
    "Python 3.7.4 (default, Aug 13 2019, 15:17:50)\n",
    "[Clang 4.0.1 (tags/RELEASE_401/final)] :: Anaconda, Inc. on darwin\n",
    "Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n",
    ">>> \n",
    "```\n",
    "then you can just type your code or paste it from a text file.\n",
    "\n",
    "* You can use something like `idle`,`spyder` or any other Python flavoured development environment you prefer.\n",
    "* We are generally using `jupyter-lab`, a recent update of the `jupyter-notebook` environment. \n",
    "* Use Python 3, as 2 is being depreciated and 1 is dead - differences are minor and Google is your friend.\n",
    "* For your own computer, we recommend installing **Anaconda**, as it provides everything you could need for computational physics in Python.\n",
    "\n",
    "![jupyter](images/jupyter.png)\n",
    "![anaconda](images/anaconda.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Python programming\n",
    "=================================\n",
    "\n",
    "## Coding tips\n",
    "\n",
    "* Include comments - even if no-one else uses the code, when you need to use something after a year or more, you will be very happy you added sensible comments.\n",
    "* Keep it simple and readable *unless* there is a very good efficiency reason not to.\n",
    "* Document your code - for anything beyond the very simple, a manual can be the difference between death and everlasting (computational) life. For more complex codes, tutorials are also critical.\n",
    "* If you do all of this, make it **open** and enjoy interacting with the whole computational physics world.\n",
    "\n",
    "<!-- ![Git](images/git.jpg) -->\n",
    "![GitHub](images/github.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# More resources\n",
    "\n",
    "For more (and almost endless options) you can begin with the [official Python tutorial](https://docs.python.org/3/tutorial/index.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Functions, packages and modules\n",
    "-------------------------------\n",
    "\n",
    "While many useful mathematical functions can usually be evaluated with a combination of standard Python commands, it is often easier and computationally more efficient to use imported functions from a package. Lists of common packages and the functions they contain can be easily obtained from Python documentation, but `math` is an obviously useful beginning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While you can import all functions from a given package:\n",
    "\n",
    "```python\n",
    "from math import *\n",
    "```\n",
    "\n",
    "```python\n",
    "import math\n",
    "x = math.sqrt(10)\n",
    "```\n",
    "\n",
    "this is generally dangerous, as you may be including duplicate functions you are unaware of. Much better to begin your code with an import of everything you will actually use. This is also generally easier to read than using modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log,cos,sqrt,pi\n",
    "\n",
    "bored_var = int(input(\"Enter your level of interest in this course (1-10): \"))\n",
    "\n",
    "if bored_var>10:\n",
    "    print(\"You are lying.\")\n",
    "    bored_var = cos(pi)\n",
    "    print(bored_var)\n",
    "elif bored_var<1:\n",
    "    print(\"You are dying.\")\n",
    "    bored_var = sqrt(pi)\n",
    "    print(bored_var)\n",
    "else:\n",
    "    while bored_var<10:\n",
    "        print(\"Be happy!\")\n",
    "        bored_var = bored_var + log(10)\n",
    "        print(bored_var)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Lists and arrays\n",
    "----------------\n",
    "\n",
    "Once we move into handling real data from a physical problem, it is hardly practical to assign every value to a different variable, and the use of *containers* becomes important. Python has both *lists* and *arrays*, and they are suited to different tasks commonly encountered in computational physics.\n",
    "\n",
    "* Lists...\n",
    "    * contain elements which can be of any type e.g. `int`,`float`.\n",
    "    * can have elements added and remove after creation.\n",
    "    * are one-dimensional.\n",
    "* Arrays...\n",
    "    * contain elements of the same type.\n",
    "    * have a fixed numbed of elements.\n",
    "    * can have any dimension.\n",
    "    * behave properly with respect to arithmetic operations.\n",
    "    * are computationally more efficient than lists.\n",
    "\n",
    "### List example\n",
    "\n",
    "Let's define a simple list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_list = list(range(1,11))\n",
    "print(simple_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just a list of integers, produced using the `range` function and converted to a list. Then there a several functions that work directly on lists:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Arrays\n",
    "\n",
    "For most problems, arrays are likely to be more useful as we are commonly dealing with well-defined data sizes and physical quantities e.g. vectors. In Python the tools for manipulating arrays are contained within the *numpy* package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import zeros,ones,empty\n",
    "zero_mat = zeros([3,3],float)\n",
    "one_mat = ones([3,3],float)\n",
    "empty_mat = empty([3,3],float)\n",
    "print(zero_mat)\n",
    "print(one_mat)\n",
    "print(empty_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Note that `empty` does not create an *empty* array, it just uses whatever numbers it has in memory. \n",
    "* Both the `zeros` and `ones` functions actually use time to create, so if you just need an empty array ready to be filled, `empty` is more efficient. \n",
    "* But remember it will not actually be **empty**..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_mat = one_mat - empty_mat\n",
    "print(sub_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then you can also use the `map` function to apply any function to a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import exp\n",
    "exp_list = list(map(exp,simple_list))\n",
    "print(exp_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Reading data into arrays\n",
    "\n",
    "Most often you will want to read in the values of an array from a external source, such as a text file. \n",
    "\n",
    "Here we can combine some of the previous lists we generated into an array (assuming they have the same length) and use this as our *data*. We will then write it to a file and read it again...which obviously makes no sense, but demonstrates the functions needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array,loadtxt,savetxt\n",
    "print(\"List 1\",simple_list)\n",
    "print(\"List 2\",exp_list)\n",
    "output_array = array([simple_list,exp_list],float)\n",
    "print(\"Combined array\")\n",
    "print(output_array)\n",
    "savetxt(\"array_data.txt.gz\",output_array) # save in gzipped format, since the data is so huge...\n",
    "input_array = loadtxt(\"array_data.txt\",float)\n",
    "print(\"Read array\")\n",
    "print(input_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Example - Weathered\n",
    "\n",
    "* Let's try and get our own data, read it in and analyze it using Python. \n",
    "* You can use whatever you want, but we will use a simple CSV file containing weather data for this example.\n",
    "\n",
    "It has this format:\n",
    "\n",
    "```\n",
    "Year,m,d,Time,Time zone,Maximum temperature (degC)\n",
    "2004,7,15,00:00,UTC,18.5\n",
    "2004,7,16,00:00,UTC,21.3\n",
    "2004,7,17,00:00,UTC,20.6\n",
    "2004,7,18,00:00,UTC,21.9\n",
    "2004,7,19,00:00,UTC,23.2\n",
    "2004,7,20,00:00,UTC,20.3\n",
    "....\n",
    "```\n",
    "\n",
    "and can be parsed like this:\n",
    "\n",
    "```python\n",
    "from numpy import array,loadtxt\n",
    "weather_array = loadtxt('weather.txt', skiprows=1, delimiter=',', usecols=(0,5), unpack=True, dtype=None)\n",
    "```\n",
    "Now calculate the number of values in your data, the sum of them and the arithmetic mean...or whatever you thinks makes sense for the data you are using. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%timeit # comment out print statements when testing speed. This is an iPython magic function.\n",
    "from numpy import loadtxt,mean\n",
    "weather_array = loadtxt('weather.txt', skiprows=1, delimiter=',', usecols=(0,5), unpack=True, dtype=None)\n",
    "\n",
    "weather_mean = sum(weather_array[1])/len(weather_array[1])\n",
    "weather_2004 = []\n",
    "weather_2005 = []\n",
    "rng = range(len(weather_array[1]))\n",
    "\n",
    "for n in rng:\n",
    "   if (weather_array[0,n] == 2004):\n",
    "       weather_2004.append(weather_array[1,n])\n",
    "   elif (weather_array[0,n] == 2005):\n",
    "       weather_2005.append(weather_array[1,n])\n",
    "\n",
    "weather2004_mean = sum(weather_2004)/len(weather_2004)\n",
    "weather2005_mean = sum(weather_2005)/len(weather_2005)\n",
    "\n",
    "print(\"Mean temperature:\",weather_mean)\n",
    "print(\"2004 mean:\",weather2004_mean)\n",
    "print(\"2005 mean:\",weather2005_mean)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "While this is an intuitive (*old school* perhaps) way to solve the problem, it is not a very *pythonic* approach to the problem...it can also be done as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%timeit # comment out print statements when testing speed\n",
    "from numpy import loadtxt,mean,where\n",
    "weather_array = loadtxt('weather.txt', skiprows=1, delimiter=',', usecols=(0,5), unpack=True, dtype=None)\n",
    "\n",
    "weather_mean = weather_array[1, :].mean()\n",
    "weather2004_mean = weather_array[1, where(weather_array[0] == 2004)].mean()\n",
    "weather2005_mean = weather_array[1, where(weather_array[0] == 2005)].mean()\n",
    "print(\"Mean temperature:\", weather_mean)\n",
    "print(\"2004 mean:\", weather2004_mean)\n",
    "print(\"2005 mean:\", weather2005_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The approach you choose should really balance readability and efficiency...but for the latter, you should really only worry about functions that are used heavily."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Graphics and visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is already evident for several examples that we have looked at that it would be useful to have ways to visualize the data and for real problems this is normally the key to actually getting to the science. Let's start by plotting perhaps the most classic of functions, `sin`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import sin,linspace # generally these are faster than the in-built Python functions\n",
    "import matplotlib.pyplot as plt # useful for functions you will use a lot, but be careful that you don't lose track\n",
    "\n",
    "x = linspace(0,10,100) # create a float array with values from 0 - 10 with 100 intervals\n",
    "y = sin(x)\n",
    "\n",
    "plt.plot(x,y,'ro') # plot a dashed line in red\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is clearly very basic, but the options with the matplotlib library are very extensive (and there is a wealth on information online explaining them) and we can easily add a lot more information in the same manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import sin,cos,exp,linspace \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "x = linspace(0,10,100) \n",
    "y_sin = sin(x)\n",
    "y_cos = cos(x)\n",
    "y_exp = 1/exp(x)\n",
    "\n",
    "plt.figure(figsize=(7.5,5)) # set the figsize\n",
    "plt.rc('font',size=16) # set the font size\n",
    "\n",
    "plt.plot(x,y_sin,'b--',label='sin(x)')\n",
    "plt.plot(x,y_cos,'m--',label='cos(x)') # adds the second plot to the graph, then we plot the whole lot at the end with show()\n",
    "plt.plot(x,y_exp,'r--',label=r'$\\frac{1}{\\exp(x)}$') # the 'r' forces this to be read as a raw string and the '\\' is ignored by Python.\n",
    "\n",
    "plt.title('The classics',fontsize=20)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Function(x)')\n",
    "plt.legend(fontsize=12)\n",
    "\n",
    "plt.show() # notice that we don't need to include this in a Jupyter notebook, but it is good practice.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Fourier transforms\n",
    "\n",
    "The Fourier transform is one of the most important, and widely used, tools in traditional theoretical physics, and it is also very useful in scientific analysis. \n",
    "\n",
    "In general, it allows us to break down functions (or signals) into the components for analysis, smoothing or filtering, and it also allows us to greatly increase the speed of certain calculations e.g. the diffusion equation or the Schrödinger equation. \n",
    "\n",
    "![Fourier cat](images/fourier.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Discrete cosine transforms\n",
    "\n",
    "For generality we introduced the complex form of the Fourier transform, but there are many practical cases where it makes more sense to use the cosine transform (the sine form is much more rarely used since it requires the function to be zero at $x=0$ and $x=L$). If we return to the cosine series:\n",
    "\n",
    "$$f(x)=\\sum_{n=0}^{\\infty}\\alpha _k cos\\left(\\frac{2 \\pi kx }{L}\\right)$$\n",
    "\n",
    "we already noted that this is only valid for even functions i.e. those that are symmetric about the midpoint. This might initially seem a major flaw, but any function can be made even by adding it to a *mirror image* of itself and then repeating it. This means that the number of samples, $N$, is also always even."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Once we have a symmetric function, it is simply a special case for $c_k$ when $y_n$ is symmetric about $x=\\frac{1}{2}L$ with $y_n=y_{N-n}$ for all $n$. Given that $N$ is even, we can rewrite the equation for the coefficients as follows (noting that $e^{i2\\pi k}=1$ for all integer $k$):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$c_k = \\sum_{n=0}^{N-1}y_n \\exp \\left(-i\\frac{2 \\pi kn }{N}\\right)$$\n",
    "\n",
    "$$= \\sum_{n=0}^{\\frac{1}{2}N}y_n \\exp \\left(-i\\frac{2 \\pi kn }{N}\\right) + \\sum_{n=\\frac{1}{2}N+1}^{N-1}y_n \\exp \\left(-i\\frac{2 \\pi kn }{N}\\right)$$\n",
    "\n",
    "$$= \\sum_{n=0}^{\\frac{1}{2}N}y_n \\exp \\left(-i\\frac{2 \\pi kn }{N}\\right) + \\sum_{n=\\frac{1}{2}N+1}^{N-1}y_{N-n} \\exp \\left(i\\frac{2 \\pi k(N-n) }{N}\\right)$$\n",
    "\n",
    "Making a change of variables such that $N-n \\rightarrow n$ and using the identity $cos\\theta = \\frac{1}{2}(e^{-i\\theta}+e^{i\\theta})$ we get the *discrete cosine transform (DCT)*:\n",
    "\n",
    "$$c_k = \\sum_{n=0}^{\\frac{1}{2}N}y_n \\exp \\left(-i\\frac{2 \\pi kn }{N}\\right) + \\sum_{n=1}^{\\frac{1}{2}N-1}y_n \\exp \\left(i\\frac{2 \\pi kn }{N}\\right)$$\n",
    "\n",
    "$$= y_0 + y_{\\frac{N}{2}}cos\\left(\\frac{2\\pi k(\\frac{N}{2})}{N} \\right) + 2\\sum_{n=1}^{\\frac{1}{2}N-1}y_n cos \\left(\\frac{2 \\pi kn }{N}\\right) $$\n",
    "\n",
    "The inverse of this is very similar, differing only by the leading $\\frac{1}{N}$ term:\n",
    "\n",
    "$$y_n = \\frac{1}{N}\\left[ c_0 + c_{\\frac{N}{2}}cos\\left(\\frac{2\\pi k(\\frac{N}{2})}{N} \\right) + 2\\sum_{n=1}^{\\frac{1}{2}N-1}c_k cos \\left(\\frac{2 \\pi kn }{N}\\right)\\right] $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Note that it is common to see DCT formulations where the sampling is taken at the *midpoint* of the sample intervals, known at a \"Type-II\" DCT, which is effectively the same, but implies that $y_n = y_{N-1-n}$ and for an even $N$:\n",
    "\n",
    "$$c_k= \\sum_{n=0}^{\\frac{1}{2}N-1}y_n \\exp \\left(-i\\frac{2\\pi kn}{N}\\right) + \\sum_{n=\\frac{1}{2}N}^{N-1}y_n \\exp \\left(-i\\frac{2\\pi kn}{N}\\right)$$\n",
    "\n",
    "$$= \\exp \\left(i\\frac{\\pi k}{N}\\right) \\left[ \\sum_{n=0}^{\\frac{1}{2}N-1}y_n \\exp \\left(-i\\frac{2\\pi k(n+\\frac{1}{2})}{N}\\right) + \\sum_{n=\\frac{1}{2}N}^{N-1}y_{N-1-n} \\exp \\left(i\\frac{2\\pi k(N-\\frac{1}{2}-n)}{N}\\right) \\right]$$\n",
    "\n",
    "$$= \\exp \\left(i\\frac{\\pi k}{N}\\right) \\left[ \\sum_{n=0}^{\\frac{1}{2}N-1}y_n \\exp \\left(-i\\frac{2\\pi k(n+\\frac{1}{2})}{N}\\right) + \\sum_{n=0}^{\\frac{1}{2}N-1}y_{n} \\exp \\left(i\\frac{2\\pi k(n+\\frac{1}{2})}{N}\\right) \\right]$$\n",
    "\n",
    "$$= 2\\exp \\left(i\\frac{\\pi k}{N}\\right) \\sum_{n=0}^{\\frac{1}{2}N-1}y_n cos \\left(\\frac{2\\pi k(n+\\frac{1}{2})}{N}\\right) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Conventionally the leading phase factor is included in the Fourier coefficients such that:\n",
    "\n",
    "$$a_k = 2 \\sum_{n=0}^{\\frac{1}{2}N-1}y_n cos \\left(\\frac{2\\pi k(n+\\frac{1}{2})}{N}\\right) $$\n",
    "\n",
    "and the inverse is:\n",
    "\n",
    "$$y_n=  \\frac{1}{N}\\left[ a_0 + 2\\sum_{k=1}^{\\frac{1}{2}N-1}a_k cos \\left(\\frac{\\pi k(n+\\frac{1}{2})}{N}\\right)\\right]$$\n",
    "\n",
    "redefining $\\frac{1}{2}N \\rightarrow N$ and $a_k \\rightarrow 2a_k$ this is often written as follows:\n",
    "\n",
    "$$a_k= \\sum_{n=0}^{N-1}y_n cos \\left(\\frac{\\pi k(n+\\frac{1}{2})}{N}\\right), y_n=  \\frac{1}{N}\\left[ a_0 + 2\\sum_{k=1}^{N-1}a_k cos \\left(\\frac{\\pi k(n+\\frac{1}{2})}{N}\\right)\\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### DCT and compression\n",
    "\n",
    "DCTs are behind a lot the original compression algorithms used in music, image and video files. \n",
    "\n",
    "* In particular JPEGs are constructed by dividing an image in to blocks, performing DCTs on these blocks and then filtering the resultant coefficients to remove *small* contributions to the signal. \n",
    "* When you open a JPEG file it applies a version of an iDCT to reconstruct the original image from the stored coefficients, including compression artifacts if important coefficients have been discarded. \n",
    "* MP3s take the filtering to the next stage by keeping coefficients that makes sense from the perspective of what the human ear can hear. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Two-dimensional Fourier transforms\n",
    "\n",
    "Before we explore the potential of Fourier transforms for 2D data, it is worth looking a little at the basic equations behind it. For a 2D function $f(x,y)$, we need to transform first with respect to $x$ and then with respect to $y$. If we have an $M \\times N$ grid of data, we first perform an ordinary Fourier transform on each of the $M$ rows:\n",
    "\n",
    "$$c^\\prime_{ml} = \\sum_{n=0}^{N-1}y_{mn} \\exp \\left(-i\\frac{2 \\pi ln }{N}\\right)$$\n",
    "\n",
    "For each row $m$ we now have $N$ coefficients, one for each value of $l$. Next we take the $l$th coefficient in each of the $M$ rows and Fourier transform these $M$ values again to get:\n",
    "\n",
    "$$c_{kl} = \\sum_{m=0}^{M-1}c^\\prime_{ml} \\exp \\left(-i\\frac{2 \\pi km }{M}\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "If we now combine these, we can formulate a complete expression for the Fourier transform in 2D:\n",
    "\n",
    "$$c_{kl} = \\frac{1}{MN}\\sum_{m=0}^{M-1}\\sum_{n=0}^{N-1}y_{mn} \\exp \\left[-i2\\pi \\left(\\frac{km}{M}+\\frac{ln}{N}\\right)\\right]$$\n",
    "\n",
    "with the corresponding inverse transform as follows:\n",
    "\n",
    "$$y_{mn} = \\frac{1}{MN}\\sum_{m=0}^{M-1}\\sum_{n=0}^{N-1}c_{kl} \\exp \\left[i2\\pi \\left(\\frac{km}{M}+\\frac{ln}{N}\\right)\\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can see this in action by coding (a very basic) compression algorithm for an image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import empty,arange,exp,real,imag,pi,array,place,argwhere,size\n",
    "from numpy.fft import rfft,irfft\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "# Numpy does not have DCT directly, so we have to do it manually - note that scipy does have it, but this is a useful teaching example\n",
    "######################################################################\n",
    "# 1D DCT Type-II function\n",
    "\n",
    "def dct(y):\n",
    "    N = len(y)\n",
    "    y2 = empty(2*N,float) # create an empty array for the function\n",
    "    y2[:N] = y[:] # the first N elements of y2 are taken from y\n",
    "    y2[N:] = y[::-1] # the elements after N are reversed giving us a symmetric, even function\n",
    "\n",
    "    c = rfft(y2) # perform the fourier transform. This uses a numpy function (Real Fast Fourier Transform), otherwise everything takes too long - we will discuss it later.\n",
    "    phi = exp(-1j*pi*arange(N)/(2*N)) # create an array with terms from (0-999) and use it to define the leading phase factor\n",
    "    return real(phi*c[:N]) # return the real part of the transform\n",
    "\n",
    "######################################################################\n",
    "# 2D DCT function\n",
    "\n",
    "def dct2(y):\n",
    "    M = y.shape[0] # first dimension of input function, use to define limits\n",
    "    N = y.shape[1] # second dimension of input function, use to define limits\n",
    "    a = empty([M,N],float) # create arrays to store our result - a for the first transform and b for the second\n",
    "    b = empty([M,N],float)\n",
    "\n",
    "# run the 1D transforms\n",
    "    for i in range(M):\n",
    "        a[i,:] = dct(y[i,:])\n",
    "    for j in range(N):\n",
    "        b[:,j] = dct(a[:,j])\n",
    "\n",
    "    return b\n",
    "\n",
    "######################################################################\n",
    "# 1D inverse DCT Type-II function\n",
    "\n",
    "def idct(a):\n",
    "    N = len(a)\n",
    "    c = empty(N+1,complex)\n",
    "\n",
    "    phi = exp(1j*pi*arange(N)/(2*N))\n",
    "    c[:N] = phi*a\n",
    "    c[N] = 0.0\n",
    "    return irfft(c)[:N] # (Inverse Real Fast Fourier Transform)\n",
    "\n",
    "######################################################################\n",
    "# 2D inverse DCT function\n",
    "\n",
    "def idct2(b):\n",
    "    M = b.shape[0]\n",
    "    N = b.shape[1]\n",
    "    a = empty([M,N],float)\n",
    "    y = empty([M,N],float)\n",
    "\n",
    "    for i in range(M):\n",
    "        a[i,:] = idct(b[i,:])\n",
    "    for j in range(N):\n",
    "        y[:,j] = idct(a[:,j])\n",
    "\n",
    "    return y\n",
    "\n",
    "adam = plt.imread('images/photo.tiff') # Read in TIFF picture file. TIFF is lossless, so generally very large compared to compressed formats.\n",
    "\n",
    "singch_adam = adam[:, :, 0] # slice image into a single channel so the transform can handle it.\n",
    "plt.figure(figsize=(12,6)) # set the figsize\n",
    "\n",
    "# plot the original image\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(singch_adam, cmap=\"plasma\") # a default colourmap is applied, there are no colour channels in the data anymore\n",
    "plt.colorbar()\n",
    "adam_dct = dct2(singch_adam) # apply the 2D DCT to the single channel image\n",
    "\n",
    "# plot the DCT of the image, limiting the scale so we can actually see something\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(adam_dct, cmap=\"plasma\",clim=(0, 1e4))\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "# define a threshold for cutting the coefficients\n",
    "cutoff_amplitude = 1e6 # \n",
    "place(adam_dct, abs(adam_dct) < cutoff_amplitude, [0]) # Put zeroes into array based on cutoff\n",
    "original_size = adam_dct.shape[0]*adam_dct.shape[1]\n",
    "components_removed = argwhere(abs(adam_dct) < cutoff_amplitude).shape[0] # Replace values below cutoff with 0\n",
    "\n",
    "# give some nice output on how much we have cut from the DCT\n",
    "percent_removed = (1-components_removed/original_size)*100\n",
    "print(\"Removed {} out of {} components. Image contains {:.2f}% of the original components.\".format(components_removed, original_size, percent_removed))\n",
    "\n",
    "plt.figure(figsize=(12,6)) # set the figsize\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(adam_dct, cmap=\"plasma\",clim=(0, 1e4))\n",
    "plt.colorbar()\n",
    "\n",
    "adam_idct = idct2(adam_dct) # run the inverse DCT on the coefficients to generate the \"compressed\" image\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(adam_idct, cmap=\"plasma\")\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "# now actually remove all the zeroes so that we are really handling a smaller array\n",
    "adam_compressed = coo_matrix(adam_dct)\n",
    "print(\"Now we have really reduced the array to {:.2f}% of its original size.\".format(100*size(adam_compressed)/size(adam_dct)))\n",
    "\n",
    "# but to actually do anything with it, we need to decompress it and see whether we lost any data.\n",
    "adam_decomp = adam_compressed.toarray()\n",
    "\n",
    "plt.figure(figsize=(12,6)) # set the figsize\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(adam_decomp, cmap=\"plasma\",clim=(0, 1e4))\n",
    "plt.colorbar()\n",
    "\n",
    "adam_idct_decomp = idct2(adam_decomp)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(adam_idct_decomp, cmap=\"plasma\")\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.imsave('images/photo_compressed',adam_idct_decomp, format='tiff') # but this is still the same size, as we had to decompress it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Tutorials\n",
    "=====================\n",
    "\n",
    "\n",
    "1. Make sure you can run the simple python examples in the first part of the introduction - explore whether you prefer the simplicity of the command line or the options in Jupyter.\n",
    "2. Select a data file from `examples/data` (or use your own) and parse it into an array. Calculate some properties from the data e.g. average, sum.\n",
    "3. Select an image file from `examples/images` (or use your own) and compress it using the simple Fourier approach. Explore how the parameters affect the quality and ultimate size of the compressed image.\n",
    "4. OpenCV computer vision applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### OpenCV\n",
    "\n",
    "OpenCV (Open Source Computer Vision Library) is a library of programming functions aimed at real-time computer vision.\n",
    "\n",
    "![openCV](images/opencv.png)\n",
    "\n",
    "Here we touch on some simple examples, but there are a wide variety of increasing complexity available from the [web](https://docs.opencv.org/4.x/d9/df8/tutorial_root.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "afm_data = cv2.imread(\"images/afm_data.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualising the image\n",
    "cv2.imshow(\"img1\", afm_data)\n",
    "\n",
    "# necessary to avoid python kernel crashing \n",
    "cv2.waitKey(0) # waits for any key press\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ??s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video in OpenCV\n",
    "\n",
    "As a video example for OpenCV, we can design a heartrate monitor. This monitor uses brightly backlight video of finger, pressed at the camera lens, and calculates the heartrate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('examples/data/heart_rate.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    # if frame is read correctly ret is True\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "    data.append(np.mean(frame[:, :, 2]))\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(np.abs(dct(data)))\n",
    "ax.set_ylim([0, 500])\n",
    "ax.set_xlim([0, 300])\n",
    "\n",
    "ax.set_xlabel(\"dct coefficient\")\n",
    "ax.set_ylabel(\"coefficient magnitude\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenCV object tracking\n",
    "\n",
    "In this tutorial, we will use OpenCV to track objects in videos. We will use [back projection](https://docs.opencv.org/3.4/da/d7f/tutorial_back_projection.html) and meanshift to find the location of the region of interest.\n",
    "\n",
    "The intuition behind the meanshift is simple. Consider you have a set of points. (It can be a pixel distribution like histogram backprojection). You are given a small window (may be a circle) and you have to move that window to the area of maximum pixel density (or maximum number of points). It is illustrated in the simple image given below:\n",
    "\n",
    "![meanshift schematic.](images/meanshift_basics.jpg)\n",
    "\n",
    "The initial window is shown in blue circle with the name \"C1\". Its original center is marked in blue rectangle, named \"C1_o\". But if you find the centroid of the points inside that window, you will get the point \"C1_r\" (marked in small blue circle) which is the real centroid of the window. Surely they don't match. So move your window such that the circle of the new window matches with the previous centroid. Again find the new centroid. Most probably, it won't match. So move it again, and continue the iterations such that the center of window and its centroid falls on the same location (or within a small desired error). So finally what you obtain is a window with maximum pixel distribution. It is marked with a green circle, named \"C2\". As you can see in the image, it has maximum number of points.\n",
    "The whole process is demonstrated on a static image below:\n",
    "\n",
    "![meanshift on back projection.](images/meanshift_face.gif)\n",
    "\n",
    "So we normally pass the histogram backprojected image and initial target location. When the object moves, obviously the movement is reflected in the histogram backprojected image. As a result, the meanshift algorithm moves our window to the new location with maximum density.\n",
    "\n",
    "This tutorial is based on [OpenCV meanshift tutorial](https://docs.opencv.org/4.x/d7/d00/tutorial_meanshift.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# capturing video\n",
    "cap = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we take the first frame, and establish a random region of interest. We will perform operations in HSV space, so that we can mask low light. We store a histogram of only the hue channel, and define a termination criteria for meanshift iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take first frame of the video\n",
    "ret,frame = cap.read()\n",
    "# setup initial location of window\n",
    "x, y, w, h = 30, 20, 100, 50 # simply hardcoded the values\n",
    "track_window = (x, y, w, h)\n",
    "# set up the ROI for tracking\n",
    "roi = frame[y:y+h, x:x+w]\n",
    "hsv_roi =  cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "mask = cv2.inRange(hsv_roi, np.array((0., 60.,32.)), np.array((180.,255.,255.)))\n",
    "roi_hist = cv2.calcHist([hsv_roi],[0],mask,[180],[0,180])\n",
    "cv2.normalize(roi_hist,roi_hist,0,255,cv2.NORM_MINMAX)\n",
    "# Setup the termination criteria, either 10 iteration or move by at least 1 pt\n",
    "term_crit = ( cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In an infinite loop, we grab next frames, convert them into hsv, and calculate a back projection with the stored histogram. Using the back projection, and previous track window, we iterate to find new window using meanshift.\n",
    "\n",
    "We also added a way to capture mouse double-click. When we left double-click a point of interest in the video output, new x, y (mouseX, mouseY) are grabbed. And when spacebar is pressed, a new histogram is generated from the new region of interest. And then the algorithm tracks the new object.\n",
    "\n",
    "..Note: press escape to exit the video output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialising a window, with Mouse click callback\n",
    "def get_mouse_event(event,x,y,flags,param):\n",
    "    \"\"\"\n",
    "    Standard mouse event callback function to capture double click position\n",
    "    \"\"\"\n",
    "    global mouseX,mouseY\n",
    "    if event == cv2.EVENT_LBUTTONDBLCLK:\n",
    "        mouseX,mouseY = x,y\n",
    "cv2.namedWindow('image')\n",
    "cv2.setMouseCallback('image',get_mouse_event)\n",
    "\n",
    "# initial mouse values\n",
    "mouseX, mouseY = 30, 20\n",
    "\n",
    "# starting infinite loop video capture and process\n",
    "while(1):\n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    "        # calculate back projection in Hue space\n",
    "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "        dst = cv2.calcBackProject([hsv],[0],roi_hist,[0,180],1)\n",
    "        # apply meanshift to get the new location\n",
    "        ret, track_window = cv2.meanShift(dst, track_window, term_crit)\n",
    "        # Draw it on image\n",
    "        x,y,w,h = track_window\n",
    "        img2 = cv2.rectangle(frame, (x,y), (x+w,y+h), 255,2)\n",
    "        cv2.imshow('image',img2)\n",
    "        k = cv2.waitKey(30) & 0xff\n",
    "        if k == 27:\n",
    "            # if escape is pressed\n",
    "            break\n",
    "        elif k == ord(' '):\n",
    "            # if spacebar is pressed, then change window and roi hist to the mouse double click point\n",
    "            x, y, w, h = mouseX, mouseY, 100, 50 # grab from double click\n",
    "            track_window = (x, y, w, h)\n",
    "            # set up the ROI for tracking\n",
    "            roi = frame[y:y+h, x:x+w]\n",
    "            hsv_roi =  cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "            mask = cv2.inRange(hsv_roi, np.array((0., 60.,32.)), np.array((180.,255.,255.)))\n",
    "            roi_hist = cv2.calcHist([hsv_roi],[0],mask,[180],[0,180])\n",
    "            cv2.normalize(roi_hist,roi_hist,0,255,cv2.NORM_MINMAX)\n",
    "    else:\n",
    "        break\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "rise": {
   "enable_chalkboard": true,
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
